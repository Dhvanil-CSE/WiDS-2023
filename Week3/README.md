# Week-3 Resources

During this week, we are set to build a comprehensive neural network, leveraging knowledge from both the previous and current weeks. Our focus will be on incorporating linear layers in our models, utilizing different activation functions and losses to train the model on the MNIST dataset. To ensure everyone is well-prepared, I encourage you to thoroughly engage with the resources provided thus far. The assignment for this week will provide hands-on experience in creating a neural network. I will give you a better insight into the model you are supposed to make in a few days. Additionally, we will be hosting a meeting to discuss important aspects related to the final project.

1. **Machine Learning Process:**
   Watch the video tutorial on the machine learning process [at this link](https://youtu.be/UoYO-MjqiVQ?feature=shared). Understanding the steps involved in machine learning is crucial for effectively applying the knowledge gained from the "Neural Networks and Deep Learning" course.

2. **Neural Networks and Deep Learning Course:**
   Prioritize completing the "Neural Networks and Deep Learning" course by Andrew Ng on Coursera. The course covers fundamental concepts in deep learning and is an essential foundation for further exploration in the field.
   - To access the course for free, audit the content through the following link: [Neural Networks and Deep Learning on Coursera](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning).

3. **Activation Functions:**
   Familiarize yourself with activation functions by reviewing the information provided [here](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6). Activation functions play a crucial role in neural networks, and understanding them is vital for model optimization.

4. **Loss Functions:**
   Explore common loss functions in machine learning by visiting [this link](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23). A solid grasp of different loss functions is essential for evaluating the performance of your neural network models.

5. **MNIST Database:**
   Since we will be working with the MNIST dataset, I encourage you to gain insights into it by reading about it on [Wikipedia](https://en.wikipedia.org/wiki/MNIST_database). The MNIST dataset is widely used for training and testing in the field of deep learning, making it valuable for hands-on experience and practical application.

6. **One Hot Encoding:**
   One hot encoding is a technique that we use to represent categorical variables as numerical values in a machine learning model. 
   - Learn more: [Geeks for Geeks - One Hot Encoding](https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/)

Completing these tasks in the specified order will provide you with a well-rounded understanding of key concepts in neural networks and deep learning, enabling you to apply this knowledge effectively in your machine learning endeavors.
